\section{Comparative Analysis of Robot Control Techniques}
\label{section:robot_control_techniques}

This section covers the study and implementation of velocity controllers for the robot manipulator as alternatives to MoveIt. Using velocities instead of positions allows for smoother and more natural movements, which are essential for human-robot collaboration and tracking a moving goal.

\subsection{Robot Communication}

The available code for controlling the UR10e robot manipulator used the MoveIt package, which would then use the ur\_robot\_driver ROS package to communicate with the robot controller. This kind of communication

The UR10e robot manipulator has two forms of communication available: the Universal Robots Real-Time Data Exchange (RTDE) interface and the Universal Robots Secondary Client Interface (SCI).

The RTDE interface allows for real-time communication with the robot controller, while the SCI interface allows for more complex communication, such as sending scripts to the robot controller.

\subsection{Velocity-Based Controller}

The velocity controller was implemented using the $ur\_rtde$ Python library. This library allows for real-time communication with the robot controller and, particularly, allows control of the robot's joints using joint angular velocities and also end-effector cartesian and angular velocities.

\textcolor{red}{justify either joint or cartesian velocities}

For compatibility with the rest of the available infrastructure, the controller was implemented as a ROS node that subscribes to a $/goal$ topic which it then tracks by sending end-effector velocity commands to the robot. If the goal moves to a position that is unreachable by the robot, the controller will stop the robot and wait for the goal to move to a reachable position.

\subsection{Testing}

The velocity controller was tested by commanding the robot to track a moving goal which corresponded to the position of a human hand. Using the calibrated Orbbec Astra Pro above the collaboration cell, the hand centroid was detected using the MediaPipe library. This centroid was then used to create a ZoI on the provided depth image to calculate the 3D position of the hand. The robot was then commanded to track the hand by sending the 3D position of the hand to the ROS $tf$ that the velocity controller node was tracking.

The robot was able to track the hand with a delay of around 0.05 seconds, which is acceptable for human-robot collaboration. Furthermore, it dealt with the moving goal without stopping or slowing down showing fluid movements. However, the hand position tracking does not publish orientation information, which means that the robot was only tracking the hand position and not the hand orientation. This limitation needs to be adressed in future work.
